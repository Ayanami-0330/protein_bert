{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BENCHMARKS_DIR = '/home/nemophila/projects/protein_bert/anticrispr_benchmarks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "996 training set records, 111 validation set records, 286 test set records.\n",
      "[2026_01_31-16:39:14] Training set: Filtered out 0 of 996 (0.0%) records of lengths exceeding 510.\n",
      "[2026_01_31-16:39:14] Validation set: Filtered out 0 of 111 (0.0%) records of lengths exceeding 510.\n",
      "[2026_01_31-16:39:14] Training with frozen pretrained layers...\n",
      "Epoch 1/40\n",
      "32/32 [==============================] - 7s 68ms/step - loss: 0.4690 - val_loss: 0.3556\n",
      "Epoch 2/40\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3145 - val_loss: 0.3370\n",
      "Epoch 3/40\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.2306 - val_loss: 0.3222\n",
      "Epoch 4/40\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.2070 - val_loss: 0.3183\n",
      "Epoch 5/40\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.1798 - val_loss: 0.3377\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "Epoch 6/40\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 0.1709 - val_loss: 0.3251\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "[2026_01_31-16:39:27] Training the entire fine-tuned model...\n",
      "[2026_01_31-16:39:32] Incompatible number of optimizer weights - will not initialize them.\n",
      "Epoch 1/40\n",
      "32/32 [==============================] - 5s 84ms/step - loss: 0.2021 - val_loss: 0.3167\n",
      "Epoch 2/40\n",
      "32/32 [==============================] - 2s 57ms/step - loss: 0.1559 - val_loss: 0.3256\n",
      "\n",
      "Epoch 00002: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 3/40\n",
      "32/32 [==============================] - 2s 62ms/step - loss: 0.1351 - val_loss: 0.3334\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "[2026_01_31-16:39:41] Training on final epochs of sequence length 1024...\n",
      "[2026_01_31-16:39:41] Training set: Filtered out 0 of 996 (0.0%) records of lengths exceeding 1022.\n",
      "[2026_01_31-16:39:42] Validation set: Filtered out 0 of 111 (0.0%) records of lengths exceeding 1022.\n",
      "63/63 [==============================] - 9s 81ms/step - loss: 0.2040 - val_loss: 0.3301\n",
      "Test-set performance:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># records</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model seq len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>286</td>\n",
       "      <td>0.89571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>286</td>\n",
       "      <td>0.89571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               # records      AUC\n",
       "Model seq len                    \n",
       "512                  286  0.89571\n",
       "All                  286  0.89571"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>257</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0   1\n",
       "0  257   3\n",
       "1   16  10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from proteinbert import OutputType, OutputSpec, FinetuningModelGenerator, load_pretrained_model, finetune, evaluate_by_len\n",
    "from proteinbert.conv_and_global_attention_model import get_model_with_hidden_layers_as_outputs\n",
    "\n",
    "# ===================== 1. 修改基准名称（对应你的数据集前缀） =====================\n",
    "BENCHMARK_NAME = 'anticrispr_binary'  # 替换原signalP_binary为你的数据集前缀\n",
    "\n",
    "# A local (non-global) binary output\n",
    "OUTPUT_TYPE = OutputType(False, 'binary')\n",
    "UNIQUE_LABELS = [0, 1]  # 你的数据集也是二分类（0/1），无需修改\n",
    "OUTPUT_SPEC = OutputSpec(OUTPUT_TYPE, UNIQUE_LABELS)\n",
    "\n",
    "# ===================== 2. 定义你的数据集根目录（核心修改） =====================\n",
    "# 替换原BENCHMARKS_DIR，指向你的anticrispr_benchmarks文件夹绝对路径\n",
    "BENCHMARKS_DIR = '/home/nemophila/projects/protein_bert/anticrispr_benchmarks'\n",
    "\n",
    "# Loading the dataset\n",
    "# ===================== 3. 加载你自己的训练/测试集（路径适配） =====================\n",
    "# 加载训练集（你的anticrispr_binary.train.csv）\n",
    "train_set_file_path = os.path.join(BENCHMARKS_DIR, '%s.train.csv' % BENCHMARK_NAME)\n",
    "train_set = pd.read_csv(train_set_file_path).dropna().drop_duplicates()\n",
    "# 从训练集中拆分验证集（和原逻辑一致，按标签分层拆分）\n",
    "train_set, valid_set = train_test_split(train_set, stratify = train_set['label'], test_size = 0.1, random_state = 0)\n",
    "\n",
    "# 加载测试集（你的anticrispr_binary.test.csv）\n",
    "test_set_file_path = os.path.join(BENCHMARKS_DIR, '%s.test.csv' % BENCHMARK_NAME)\n",
    "test_set = pd.read_csv(test_set_file_path).dropna().drop_duplicates()\n",
    "\n",
    "# 打印数据集大小（验证是否加载成功）\n",
    "print(f'{len(train_set)} training set records, {len(valid_set)} validation set records, {len(test_set)} test set records.')\n",
    "\n",
    "# ===================== 以下部分无需修改（模型训练/评估逻辑通用） =====================\n",
    "# Loading the pre-trained model and fine-tuning it on the loaded dataset\n",
    "pretrained_model_generator, input_encoder = load_pretrained_model()\n",
    "\n",
    "# get_model_with_hidden_layers_as_outputs gives the model output access to the hidden layers (on top of the output)\n",
    "model_generator = FinetuningModelGenerator(pretrained_model_generator, OUTPUT_SPEC, pretraining_model_manipulation_function = \\\n",
    "        get_model_with_hidden_layers_as_outputs, dropout_rate = 0.5)\n",
    "\n",
    "training_callbacks = [\n",
    "    keras.callbacks.ReduceLROnPlateau(patience = 1, factor = 0.25, min_lr = 1e-05, verbose = 1),\n",
    "    keras.callbacks.EarlyStopping(patience = 2, restore_best_weights = True),\n",
    "]\n",
    "\n",
    "finetune(model_generator, input_encoder, OUTPUT_SPEC, train_set['seq'], train_set['label'], valid_set['seq'], valid_set['label'], \\\n",
    "        seq_len = 512, batch_size = 32, max_epochs_per_stage = 40, lr = 1e-04, begin_with_frozen_pretrained_layers = True, \\\n",
    "        lr_with_frozen_pretrained_layers = 1e-02, n_final_epochs = 1, final_seq_len = 1024, final_lr = 1e-05, callbacks = training_callbacks)\n",
    "\n",
    "# Evaluating the performance on the test-set\n",
    "results, confusion_matrix = evaluate_by_len(model_generator, input_encoder, OUTPUT_SPEC, test_set['seq'], test_set['label'], \\\n",
    "        start_seq_len = 512, start_batch_size = 32)\n",
    "\n",
    "print('Test-set performance:')\n",
    "display(results)\n",
    "\n",
    "print('Confusion matrix:')\n",
    "display(confusion_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proteinbert-tf24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
